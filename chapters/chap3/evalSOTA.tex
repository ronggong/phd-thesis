To conclude the chapter, we present an evaluation of the performance of some existing approaches in \gls{MIR} applied to automatic rhythm annotation tasks in Indian art music. Most of the content of this section comes from the paper by \citeA{ajay:14:rhythmJNMR}. The evaluation presented here is an early evaluation of the algorithms, and the goal of such an evaluation is not to compare performance of these algorithms with the proposed approaches. The goal is to obtain insights into the nature of rhythm in these cultures and the challenges to rhythm analysis, and to learn about the capabilities and limitations of the existing approaches when applied to Indian art music to further use these insights in proposing novel approaches. 

Many of these approaches were not proposed to handle the rhythmic structures encountered in Indian art music, and hence their performance is at best sub-optimal. The algorithms and the data had to be adapted to a common ground in which an evaluation could be done. Hence, the evaluations are not strict and comprehensive, but still provide insights into the approaches. 

We focus on the problems that are not explicitly addressed in subsequent chapters. In specific, meter estimation (cycle length estimation) and downbeat tracking are evaluated here. These two tasks however are implicitly addressed within the task of meter inference in \chapref{chap:meterInfTrack}. Cycle length estimation task is used as a proxy for \gls{tala} recognition. Downbeat tracking is an important focus of this dissertation, but we approach it together as a part of meter analysis, while the approaches evaluated here attempt downbeat tracking as an independent task. 

If existing methods from \gls{MIR} are capable of handling the following tasks in a satisfying way for Indian art music, we will be able to automatically analyze the content of these music signals in a well-structured way. However, as recent research results show \cite{holzapfel:12:beat}, these tasks are far from being solved even for the Eurogenetic forms of music, for which most methods have been presented. We evaluate several approaches for each of the three tasks and analyze which of those are promising in their results and can provide directions for future work. It should be pointed out here that there are algorithmic approaches which tackle more than one task in a combined way \cite[e.g.,]{klapuri:06:meter}. We will report the accuracy of individual tasks for such systems in our experiments as well. Further, it is also to be noted that we use only audio and its associated metadata in these tasks, because none of the available methods are capable of combining audio processing with the several other cues that were specified in \secref{sec:probdef:opportunities}.
\subsubsection{Datasets for evaluation}
The recordings used for evaluation in this section are a subset of the bigger CompMusic collection that is described in detail in \chapref{chap:datasets}. The CompMusic collection is a comprehensive collection representative of Indian art music, and in the context of this section, we use only a subset of the audio collection and the associated rhythm metadata from commercially available releases. The audio recordings are short clips extracted from full length pieces. 

In order to evaluate the algorithms, we need collections of audio recordings that are annotated in various aspects. For cycle length recognition we only need high-level information about the \gls{tala}, which decides the length of the \gls{tala}. For the tasks of downbeat tracking however, we need low-level annotations that specify the alignment between organized pulsation and music sample. Because no such annotated music collection was available, a collection of samples had to be manually annotated. As the process of manual annotation is very time consuming, we decided to compile a bigger set of recordings with high-level annotation and selected a smaller set of recordings for the evaluation and downbeat tracking. 

For both Hindustani and Carnatic music, recordings from four popular \glspl{tala} were selected for evaluation. The Carnatic dataset has 61, 63, 60, and 33 pieces in \gls{adi}, \gls{rupaka}, \gls{mishra chapu}, and \gls{khanda chapu} \glspl{tala}, respectively. The Hindustani dataset has 62, 61, 19, and 15 pieces in \gls{teental}, \gls{ektal}, \gls{jhaptal}, and \gls{rupak}, respectively. The Hindustani dataset has compositions in three \gls{lay} classes - \gls{vilambit}, \gls{madhyam} and \gls{dhrut}. In the datasets, the pieces are 2 minute long excerpts sampled at 44100 Hz. Though the audio recordings are stereo, they are down-mixed to mono since none of the algorithms evaluated in this study make use of additional information from stereo audio and primarily work on mono. They include instrumental as well as vocal recordings. The \gls{tala}/\gls{taal} annotation of these pieces were directly obtained from the accompanying editorial metadata contained in the CompMusic collection. 

The downbeat recognition task is evaluated only on Carnatic music, with piecess from \gls{adi} and \gls{rupaka} \gls{tala}. Thirty two examples in \gls{adi} \gls{tala} and thirty four examples in \gls{rupaka} \gls{tala} of Carnatic music have beat and sama instants manually annotated, which we refer to as the Carnatic low-level-annotated dataset. Similar to the Carnatic dataset, Carnatic low-level-annotated dataset also consists of two minute long excerpts. All annotations were manually done using Sonic visualizer~\cite{cannam:10:sv} by tapping along to a piece and then manually correcting the annotations. 
\subsection{Cycle length estimation}
\input{chapters/chap3/evalCyclelength}
%
% \subsection{Beat Tracking}
% \input{chapters/chap3/evalBeattrack}
%
\subsection{Downbeat tracking}
\input{chapters/chap3/evalDownbeat}
%
\subsection{Discussion}
\input{chapters/chap3/evalConclusions}
%
% Preliminary experiments~\cite{Ajay:CompMusic21} for tāla recognition using beat tracking emphasize the need for a culture-specific approach. We developed an algorithm that uses a beat similarity matrix and inter onset interval histogram to automatically extract the sub-beat structure and the supra-beat periodicity of a musical piece. From this information, we could obtain a rank ordered set of candidates for the tāla cycle period and the naḍe. A block diagram of the system is in Figure \ref{fig:FullBD}. The algorithm was tested on a manually annotated Carnatic music dataset (CMDB) consisting of 86 thirty second song snippets of both vocal and instrumental music with different instrumentation, set to different tālas and naḍe. The algorithm was also tested on an Indian light classical music dataset (ILCMDB) consisting of 58 semi-classical songs based on popular Hindustani \emph{ragas}. The allowed metrical level (AML)~\cite{Davies:07} recognition accuracy of the algorithm on ILCMDB was 79.3\% and 72.4\% for the naḍe and the tāla, respectively. The accuracy on the more difficult CMDB was poorer with 68.6\% and 51.1\% for naḍe and tāla, respectively. The poorer performance on CMDB can be attributed to changes in kāla (metrical level) through the song and the lack of distinct beat-level similarity in the songs of the dataset. This is quite typical in Carnatic music where the percussion accompaniment is completely free to improvise within the framework of the tāla. The performance was also poor on the songs in odd beat tālas such as Mishra Chapu and Khanda Chapu. This motivates us further to explore knowledge based approaches to tāla recognition.
%
%
% Recently, our focus mainly has been on sama estimation. The information about the sama instants of a music piece makes the other annotations tasks much simpler. The strokes of Mridangam and Tabla are quite useful for annotation tasks. We are thus exploring the use of percussion enhancement algorithms~\cite{Fitzgerald2010} on audio to obtain only percussive onsets during onset detection. Many of the phrase changes occur at the sama instants and are characterized by notable melodic, percussive, and timbral changes. However, neither of each of these changes are necessary nor sufficient indicators of sama. This motivates us to explore a hybrid approach involving the information from onsets, melody, and timbre for sama estimation (Figure \ref{fig:SamaEstimate}). For melody and timbre change point estimation, novelty functions~\cite{Foote2000a} estimated using HPCP~\cite{emilia:phd} and MFCC provide promising results. Further experimentation towards sama recognition is under progress. 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% THESIS PROPOSAL END %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% A well-formed metrical grid is often assumed to be present in Eurogenetic tonal music~\cite{lerdahl:83:generative}. Forms of music that deviate from the well-formedness in terms of meter have rarely been in the focus of computational rhythm analysis (\textit{e.g.} the work by \citeA{Antonopoulos07}). In this paper, we concentrate our studies on Carnatic and Hindustani music of India, as well as Makam music of Turkey. All the three musics have a long standing history within the respective cultures. They are also well established traditions that exist in current social context with a large audience and significant musicological literature . While each of these music traditions includes a huge variety of styles and forms in itself, we maintain a broader point of view here, and ask in how far the state of the art in rhythm analysis can present us with meaningful insights when applied to them. 
%
% Until now, in the context of Hindustani music, approaches for tempo estimation and time signature recognition were presented by Gulati et al.~\cite{gulati:10:pattern,sankalp:12:meter}, and transcription of percussive instruments was approached by \citeA{chordia:05:phdthesis} and \citeA{miron:11:thesis}. For Carnatic music, \citeA{ajay:12:beatWkShop} proposed a system to describe meter in terms of the time-span relations between pulsations at measure, beat and subdivision levels. An approach to discriminate between classes of rhythm in Turkish music was proposed by \citeA{Holzapfel09ISMIR}, which can serve as a tool for time signature recognition as well. Recently, \citeA{holzapfel:12:meterTurkWkShop} investigated how the melodies of Turkish makam music are related with the underlying rhythmic mode. Both mentioned approaches for Turkish music examined repertoire consisting of symbolic data, and to the best of our knowledge no rhythmic analysis of audio signals has been attempted for Turkish music. 
%
%\comment{The available descriptions of rhythm and meter in Indian and Turkish music imply that they differ from Eurogenetic music in terms of the time-spans at various levels of the meter hierarchy and in terms of the possibly irregular pulsation at one of the levels (see \citeA<e.g.>{clayton:00:time,ozkan:84:usul}). Therefore, in this article we address the problem of tracking the pulsations at different metrical levels, and of determining the relations between the time-spans between these levels. By doing so we can potentially derive meaningful descriptions of the metric structure of Indian and Turkish music pieces. In Section \ref{sec:problemdef} we provide the reader with the basic concepts related to meter in Turkish Makam, Carnatic and Hindustani music, and describe some of the opportunities and challenges to rhythm analysis in these music cultures. We will then define three analysis tasks motivated by the structure of meter in the three music cultures - beat tracking, cycle length recognition, and downbeat detection. As none of these tasks have been addressed before on the presented repertoire, we had to compile and annotate the music collections that are necessary for the evaluation of the analysis algorithms. The related collections and annotations will be described in Section~\ref{sec:collections}. In \secref{sec:models} we give a detailed description of all the analysis algorithms that we will evaluate for the three tasks along with description of the evaluation methods. The following Sections~\ref{sec:beat}-\ref{sec:downbeat} give the detailed results of our experiments, separately for each of the analysis tasks. In Section~\ref{sec:discussion} we sum up the results and describe what they imply for rhythm analysis in Indian and Turkish music. The final section specifies future directions for research in rhythm analysis.}
% \comment{In this part of the chapter, JNMR article is to be included. Explain the details of all algorithms and explain where they worked and where they failed. The dataset used is a bit obsolete and hence need not be included in detail here. May be push this in text within each problem discussion ??}